# ai_detector_app.py
import streamlit as st
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


# =========================
# 1. å»ºç«‹ç¤ºç¯„è³‡æ–™é›†ï¼ˆä¹‹å¾Œå¯æ›æˆè‡ªå·±çš„è³‡æ–™ï¼‰
# =========================
def build_demo_dataset():
    """
    label = 0 -> Human
    label = 1 -> AI
    å…ˆç”¨å¾ˆå°çš„ç¤ºç¯„è³‡æ–™è®“æ•´å€‹æµç¨‹å¯ä»¥è·‘é€šã€‚
    ä¹‹å¾Œå¦‚æœæœ‰è‡ªå·±çš„è³‡æ–™ï¼Œå¯ä»¥ç›´æ¥æ”¹é€™å€‹ functionã€‚
    """
    human_texts = [
        "ä»Šå¤©ä¸Šèª²çš„æ™‚å€™è€å¸«è¬›äº†å¾ˆå¤šä¾‹å­ï¼Œå…¶å¯¦æˆ‘æœ‰ä¸€é»è½ä¸å¤ªæ‡‚ï¼Œä½†å›å®¶å†çœ‹ä¸€æ¬¡æ‡‰è©²å°±å¯ä»¥äº†ã€‚",
        "æ˜¨å¤©è·Ÿæœ‹å‹å»å¤œå¸‚åƒæ±è¥¿ï¼Œäººè¶…ç´šå¤šï¼Œçµæœæ’éšŠæ’åˆ°è…³å¾ˆé…¸ã€‚",
        "æˆ‘è¦ºå¾—å¯«ä½œæœ€é›£çš„åœ°æ–¹æ˜¯è¦æŠŠè‡ªå·±çš„æƒ³æ³•æ•´ç†æ¸…æ¥šï¼Œé‚„è¦è®“åˆ¥äººçœ‹å¾—æ‡‚ã€‚",
        "å‰å¹¾å¤©çªç„¶ä¸‹å¤§é›¨ï¼Œçµæœæˆ‘å¿˜è¨˜å¸¶å‚˜ï¼Œå…¨èº«éƒ½æ·‹æ¿•ï¼Œåªå¥½è¶•å¿«å›å®¶æ´—æ¾¡æ›è¡£æœã€‚",
        "é€™å­¸æœŸçš„ä½œæ¥­æœ‰é»å¤šï¼Œæœ‰æ™‚å€™æœƒè¦ºå¾—å£“åŠ›å¾ˆå¤§ï¼Œä½†æ…¢æ…¢åšå…¶å¯¦é‚„æ˜¯å¯ä»¥å®Œæˆã€‚"
    ]

    ai_like_texts = [
        "This paragraph is generated to demonstrate the style of AI-written content, which often appears fluent and well structured.",
        "In recent years, artificial intelligence has significantly improved, enabling models to produce coherent and context-aware text.",
        "The purpose of this text is to resemble machine-generated language, with formal tone and generic statements.",
        "AI-generated content typically maintains consistent grammar and uses relatively neutral expressions throughout the paragraph.",
        "Modern language models are capable of generating long passages that sound natural, even without deep understanding of the topic."
    ]

    texts = human_texts + ai_like_texts
    labels = [0] * len(human_texts) + [1] * len(ai_like_texts)  # 0=Human, 1=AI

    df = pd.DataFrame({"text": texts, "label": labels})
    return df


# =========================
# 2. è¨“ç·´æ¨¡å‹ï¼ˆç”¨ cache é¿å…æ¯æ¬¡é‡è¨“ï¼‰
# =========================
@st.cache_resource
def train_model():
    """
    è¨“ç·´ TF-IDF + Logistic Regressionã€‚
    é€™è£¡ç”¨ç¤ºç¯„è³‡æ–™ã€‚ä¹‹å¾Œè‹¥æœ‰è‡ªå·±çš„ datasetï¼Œ
    å¯ä»¥åœ¨é€™è£¡æ”¹æˆè®€ CSV å†è¨“ç·´ã€‚
    """
    df = build_demo_dataset()
    X = df["text"].values
    y = df["label"].values  # 0 = Human, 1 = AI

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    pipeline = Pipeline([
        ("tfidf", TfidfVectorizer(
            ngram_range=(1, 2),
            max_features=5000,
            sublinear_tf=True
        )),
        ("clf", LogisticRegression(
            max_iter=1000,
            n_jobs=-1
        ))
    ])

    pipeline.fit(X_train, y_train)

    # ç°¡å–®åšä¸€ä¸‹ demo accuracyï¼Œå›å‚³çµ¦å‰ç«¯é¡¯ç¤º
    y_pred = pipeline.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    return pipeline, acc


# =========================
# 3. Streamlit ä»‹é¢
# =========================
st.set_page_config(
    page_title="AI / Human æ–‡ç« åµæ¸¬å™¨",
    page_icon="ğŸ¤–",
    layout="centered"
)

st.title("ğŸ¤– AI / Human æ–‡ç« åµæ¸¬å™¨")
st.write(
    """
    è«‹è¼¸å…¥ä¸€æ®µæ–‡ç« ï¼Œæˆ‘æœƒæ ¹æ“šè¨“ç·´å¥½çš„æ¨¡å‹ï¼Œä¼°è¨ˆé€™æ®µæ–‡å­—
    æ¯”è¼ƒåƒæ˜¯ **AI ç”¢ç”Ÿ** é‚„æ˜¯ **äººé¡æ’°å¯«**ã€‚
    
    > âš ï¸ é€™åªæ˜¯ç¤ºç¯„ç´šå°æ¨¡å‹ï¼Œä½¿ç”¨å¾ˆå°‘é‡è³‡æ–™è¨“ç·´ï¼Œ  
    > åªèƒ½ç•¶ä½œä½œæ¥­ / ç·´ç¿’ç”¨ï¼Œä¸ä»£è¡¨çœŸå¯¦ AI åµæ¸¬å™¨çš„å¯é åº¦ã€‚
    """
)

with st.expander("æ¨¡å‹è³‡è¨Šï¼ˆdemo ç”¨ï¼‰", expanded=False):
    st.write("æœ¬é é¢ä½¿ç”¨ï¼šTF-IDF + Logistic Regression")
    st.write("è¨“ç·´è³‡æ–™ï¼šç°¡å–®æ‰‹åˆ» 5 ç­† human + 5 ç­† AI é¢¨æ ¼å¥å­")

# å…ˆè¨“ç·´ / è¼‰å…¥æ¨¡å‹ï¼ˆåªæœƒåœ¨ç¬¬ä¸€æ¬¡å‘¼å«æ™‚è·‘ï¼‰
with st.spinner("åˆå§‹åŒ–æ¨¡å‹ä¸­..."):
    model, demo_acc = train_model()

st.caption(f"ï¼ˆDemo å°æ¸¬è©¦é›†æº–ç¢ºç‡ç´„ç‚ºï¼š{demo_acc*100:.1f}%ï¼‰")

text = st.text_area("âœï¸ è«‹è²¼ä¸Šè¦æª¢æ¸¬çš„æ–‡æœ¬ï¼š", height=220)

col_run1, col_run2 = st.columns([1, 1])
with col_run1:
    auto_run = st.checkbox("è¼¸å…¥æ–‡å­—å°±è‡ªå‹•åˆ†æ", value=True)
with col_run2:
    run_button = st.button("é–‹å§‹åµæ¸¬")

should_run = False
if auto_run:
    should_run = bool(text.strip())
else:
    should_run = run_button and bool(text.strip())

if should_run:
    with st.spinner("åˆ†æä¸­..."):
        proba = model.predict_proba([text])[0]  # shape: (2,)
        classes = list(model.classes_)          # e.g. [0, 1] where 1 = AI

        # å‡è¨­ï¼š0 = Human, 1 = AI
        ai_index = classes.index(1)
        human_index = classes.index(0)

        ai_prob = float(proba[ai_index])
        human_prob = float(proba[human_index])

    st.subheader("ğŸ“Š åˆ¤æ–·çµæœ")

    col1, col2 = st.columns(2)
    with col1:
        st.metric("AI ç”¢ç”Ÿæ©Ÿç‡", f"{ai_prob * 100:.1f}%")
    with col2:
        st.metric("Human æ’°å¯«æ©Ÿç‡", f"{human_prob * 100:.1f}%")

    st.write("---")
    st.write("æ©Ÿç‡è¦–è¦ºåŒ–ï¼š")

    # ç°¡å–®æ¢ç‹€åœ–
    st.bar_chart({
        "AI": [ai_prob],
        "Human": [human_prob]
    })

elif text.strip() == "" and run_button:
    st.warning("è«‹å…ˆè¼¸å…¥ä¸€äº›æ–‡æœ¬å†æŒ‰ã€Œé–‹å§‹åµæ¸¬ã€ã€‚")

